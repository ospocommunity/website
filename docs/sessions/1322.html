<!DOCTYPE HTML>

<html>
<head>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130779021-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-130779021-1');
    </script>
    <title>ApacheCon @Home</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta name="description" content=""/>
    <meta name="keywords" content=""/>

    <meta property='og:title' content='ApacheCon @Home'/>
    <meta property='og:url' content='//apachecon.com/acah2021/'/>
    <base href="https://elek.github.io/acah2021/"/>
    
    <script src="js/jquery.min.js"></script>
    <script src="js/jquery.dropotron.min.js"></script>
    <script src="js/skel.min.js"></script>
    <script src="js/skel-layers.min.js"></script>
    <script src="js/init.js"></script>
    <noscript>
        <link rel="stylesheet" href="css/skel.css"/>
        <link rel="stylesheet" href="css/style.css"/>
    </noscript>
    
</head>
<body>


<div class="wrapper style1">

    
    <div id="header">
        <div class="container">
            
            <a href="index.html"><img class="logo-img" src="images/apachecon.png" height="30" ALIGN=CENTER></a>


            
            
            <nav id="nav">
    <ul>
        <li><a href="cfp.html">Call for Presentations</a></li>
         <li><a href="https://hopin.to/events/apachecon-home">Register</a></li>
         <li><a href="http://s.apache.org/acah-tshirt">TShirt</a></li>
         <li><a href="tracks.html">Tracks</a></li>
         <li><a href="sessions.html">Schedule</a></li>
        <li><a href="conduct.html">Code of Conduct</a></li>
    </ul>
</nav>

        </div>
    </div>


    
    <div id="main" class="wrapper style4">

        
        <div id="content" class="container">
            <section>
                <header class="major">
                    <h3>Creating a Stream Data Pipeline on Google Cloud Platform using Apache Beam</h3>
                    <h4>Shuichi Suzuki</h4>
                    2019-09-12 17:30
                    <a class="label" href="tracks/beam.html">#beam</a></li>
                </header>

                <p>We built a scalable and flexible stream data pipeline for our microservices on Google Cloud Platform (GCP), using Cloud Pub/Sub, Google Cloud Storage, BigQuery, and Cloud Dataflow, using Apache Beam. The stream data pipeline is working on the production system for Mercari, one of the biggest C2C e-commerce services in Japan. The pipeline currently accepts logs from 5+ microservices, and the number will increase soon.
Our microservice architecture is based on the following three concepts:</p>
<ol>
<li>Split the log collection and data processing phases to keep the system simple.</li>
<li>Use stream processing in order to achieve low latency.</li>
<li>Don’t just accumulate raw data—support structured output that is easier to use.
Based on these concepts, we built a data pipeline in GCP.
For each microservice, we will provide a Cloud Pub/Sub “Ramp” to send logs to. Cloud Pub/Sub can have messages that contain an optional byte array in their payloads. The entire message that is ingested into the Ramp uses Cloud Dataflow streaming processing to collect them in the “RawDataHub,” a Cloud Pub/Sub topic for collection. When this happens, the PubsubMessage payload is not changed at all; the metadata necessary for subsequent processing (destination and schema information, data necessary for pipeline metrics, etc.) is provided in the PubsubMessage’s attribute map. This Dataflow job does not do processing for each service or topic—it treats all messages uniformly.
The raw data from RawDataHub is then output to two independent Cloud DataFlow streaming processes: “RawDataLake”(the infrastructure is in Google Cloud Storage, or “GCS”) and “StructuredDataHub”, another Cloud Pub/Sub topic. The StructuredDataHub has structured avro records.
The structured data from StructuredDataHub is then sent to more two independent Cloud DataFlow streaming processes: “StructuredDataLake” on GCS and “Data WareHouse” (Google BigQuery).</li>
</ol>


            </section>
        </div>
    </div>

    

<div id="footer">
  <section class="container">
    <header class="major">
      <h2>Connect with us</h2>

    </header>
    <table><tr><td><a href="https://www.facebook.com/ApacheSoftwareFoundation/">
        <img width="66" src="images/iconmonstr-facebook-6-96.png"></a></td><td>
        <a href="https://twitter.com/ApacheCon"><img width="66" src="images/iconmonstr-twitter-1-96.png"></td><td><a href="http://s.apache.org/apachecon-slack"><img width="66" src="images/slack-icon.png"></tD></tr></table>				<hr /><p>ApacheCon operates under the terms of the <a href="https://www.apache.org/foundation/policies/conduct.html">Apache Software Foundation Code of Conduct</a>. </p>
    <hr />
    <p class="byline">Copyright 2021, <a href="https://www.apache.org/">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0. <br />Apache and the Apache feather logo are trademarks of The Apache Software Foundation.</div>
    </section>
</div>
</div>

</body>
</html>

